{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对lightGBM使用交叉验证和GridSearchCV调参；\n",
    "# 调参前：0.1234，调参后：0.1220\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df5 = pd.read_csv('train_TTI_6+6+3_more.csv')\n",
    "df5['time']=pd.to_datetime(df5['time'])\n",
    "df5['month']=[x.month for x in df5['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-0.05495542791258303\n{'max_depth': 7}\n-0.060218029322634564\n{'max_depth': 7}\n-0.052792845062619026\n{'max_depth': 7}\n-0.06568675308235891\n{'max_depth': 7}\n-0.04317767192696955\n{'max_depth': 7}\n-0.046168985124148264\n{'max_depth': 7}\n-0.06246818120476807\n{'max_depth': 7}\n-0.12176774426879505\n{'max_depth': 4}\n-0.03946882163968926\n{'max_depth': 4}\n-0.061652130810510734\n{'max_depth': 7}\n-0.1478458985460462\n{'max_depth': 4}\n-0.3240937239241952\n{'max_depth': 7}\n"
    }
   ],
   "source": [
    "# 利用GridSearchCV()搜索较好的参数。\n",
    "train_train=df5\n",
    "train_train['hour']=[x.hour+x.minute/60 for x in train_train['time']] # 需要time列转化为datetime类\n",
    "#train_test['hour']=[x.hour+x.minute/60 for x in train_test['time']] # 需要time列转化为datetime类\n",
    "mae=0\n",
    "for id_road,group in train_train.groupby('id_road'):\n",
    "    #X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "    X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "    y_columns_list=['TTI6','TTI7','TTI8']\n",
    "    X=group[X_columns_list].values\n",
    "    y=group[y_columns_list].values\n",
    "    y0=y[:,0]\n",
    "    y1=y[:,1]\n",
    "    y2=y[:,2]\n",
    "    model0= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    model1= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    model2= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    params_test0={\n",
    "                #'min_child_samples': [18,19,20,21,22]\n",
    "                #'num_leaves': [31,40，5063],\n",
    "                #'max_depth': [4,7，10]\n",
    "              #'learning_rate': [0.01, 0.02,0.08,0.15],\n",
    "              #'n_estimators':[100,500,1000]\n",
    "    }\n",
    "    gsearch0=GridSearchCV(estimator=model0, param_grid=params_test0 ,scoring='neg_mean_absolute_error', cv=6)#, verbose=1, n_jobs=4)\n",
    "    gsearch0.fit(X,y0)\n",
    "    print(gsearch0.best_score_)\n",
    "    print(gsearch0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.19388257237873838\n0.104527610957374\n0.13459852580973544\n0.13056445859501145\n0.134598146756048\n0.13725844614118718\n0.1392382934396824\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "month_list=[1,2,3,10,11,12]\n",
    "mae_sum=0\n",
    "for i in month_list:\n",
    "    train_train=df5.loc[df5['month']!=i]\n",
    "    train_train.drop(['month'],axis=1,inplace=True)\n",
    "    train_test=df5.loc[df5['month']==i]\n",
    "    train_test.drop(['month'],axis=1,inplace=True)\n",
    "\n",
    "    train_train['hour']=[x.hour+x.minute/60 for x in train_train['time']] # 需要time列转化为datetime类\n",
    "    train_test['hour']=[x.hour+x.minute/60 for x in train_test['time']] # 需要time列转化为datetime类\n",
    "\n",
    "    train_train=train_train.loc[train_train['hour']>=7.5]\n",
    "    train_train=train_train.loc[train_train['hour']<=22]\n",
    "    train_test=train_test.loc[train_test['hour']>=7.5]\n",
    "    train_test=train_test.loc[train_test['hour']<=22]\n",
    "    mae=0\n",
    "    for id_road,group in train_train.groupby('id_road'):\n",
    "        #X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        y_columns_list=['TTI6','TTI7','TTI8']\n",
    "        X=group[X_columns_list].values\n",
    "        y=group[y_columns_list].values\n",
    "        y0=y[:,0]\n",
    "        y1=y[:,1]\n",
    "        y2=y[:,2]\n",
    "        model0= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        model1= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        model2= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        #model = RandomForestRegressor(max_features=\"auto\",n_estimators=50, min_samples_leaf = 10)\n",
    "        #model=DecisionTreeRegressor(criterion='mae',splitter='random',max_depth=10,min_samples_split=5,min_samples_leaf=4)\n",
    "        #model = linear_model.LinearRegression()\n",
    "        model0.fit(X, y0)\n",
    "        model1.fit(X, y1)\n",
    "        model2.fit(X, y2)\n",
    "        date_test=train_test.loc[train_test['id_road']==id_road]\n",
    "        X_test=date_test[X_columns_list].values\n",
    "        y_test=date_test[y_columns_list].values\n",
    "        y0_predict=model0.predict(X_test)\n",
    "        y1_predict=model1.predict(X_test)\n",
    "        y2_predict=model2.predict(X_test)\n",
    "        #y_predict=model.predict(X_test)\n",
    "        #err=np.abs(y_test-y_predict)\n",
    "        #mae+=np.sum(np.sum(err))\n",
    "        err0=np.abs(y_test[:,0]-y0_predict)\n",
    "        err1=np.abs(y_test[:,1]-y1_predict)\n",
    "        err2=np.abs(y_test[:,2]-y2_predict)\n",
    "        mae0=np.sum(err0)\n",
    "        mae1=np.sum(err1)\n",
    "        mae2=np.sum(err2)\n",
    "        #print(mae0/len(err0),mae1/len(err1),mae2/len(err2))\n",
    "        mae+=mae0+mae1+mae2\n",
    "    mae/=len(train_test)*3\n",
    "    print(mae)\n",
    "    mae_sum+=mae\n",
    "print(mae_sum/len(month_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.08910520428021439 0.12656957639385394 0.14481976001792557\n0.07984482707392836 0.11064597008705178 0.1284649191139318\n0.055838958768116925 0.08707099884222948 0.10634023519100656\n0.09023131271227146 0.12936658871186116 0.15532192223040095\n0.04977573191528718 0.06334475177210502 0.06927189942448385\n0.07327343917362776 0.09827919875619018 0.11193523239895035\n0.20174421104584817 0.2309332726941033 0.2450869964138369\n0.13322241849441632 0.17792269546980624 0.19582591527484589\n0.06427611962391266 0.07729850769472102 0.08266087396115586\n0.08670420687197367 0.11095820052787285 0.12588681436193577\n0.19116705421528513 0.23241630984320627 0.2481824747191277\n0.5077567762032622 0.660208707967827 0.7343277279202115\n0.16877999472685512\n0.16877999472685512\n"
    }
   ],
   "source": [
    "# 验证递推3个y是否会有提升。\n",
    "# 结论：无提升。\n",
    "\n",
    "#month_list=[1,2,3,10,11,12]\n",
    "month_list=[1]\n",
    "mae_sum=0\n",
    "for i in month_list:\n",
    "    train_train=df5.loc[df5['month']!=i]\n",
    "    train_train.drop(['month'],axis=1,inplace=True)\n",
    "    train_test=df5.loc[df5['month']==i]\n",
    "    train_test.drop(['month'],axis=1,inplace=True)\n",
    "    train_train['hour']=[x.hour+x.minute/60 for x in train_train['time']] # 需要time列转化为datetime类\n",
    "    train_test['hour']=[x.hour+x.minute/60 for x in train_test['time']] # 需要time列转化为datetime类\n",
    "    mae=0\n",
    "    for id_road,group in train_train.groupby('id_road'):\n",
    "        #X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        X1_columns_list=['TTI1','TTI2','TTI3','TTI4','TTI5','TTI6','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        X2_columns_list=['TTI2','TTI3','TTI4','TTI5','TTI6','TTI7','speed0','speed1','speed2','speed3','speed4','speed5','hour','isHoliday','weekday']\n",
    "        y_columns_list=['TTI6','TTI7','TTI8']\n",
    "        X=group[X_columns_list].values\n",
    "        X1=group[X1_columns_list].values\n",
    "        X2=group[X2_columns_list].values\n",
    "        y=group[y_columns_list].values\n",
    "        y0=y[:,0]\n",
    "        y1=y[:,1]\n",
    "        y2=y[:,2]\n",
    "        model0= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        model1= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        model2= LGBMRegressor(boosting_type='gbdt',num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "        #model = RandomForestRegressor(max_features=\"auto\",n_estimators=50, min_samples_leaf = 10)\n",
    "        #model=DecisionTreeRegressor(criterion='mae',splitter='random',max_depth=10,min_samples_split=5,min_samples_leaf=4)\n",
    "        #model = linear_model.LinearRegression()\n",
    "        model0.fit(X, y0)\n",
    "        model1.fit(X1, y1)\n",
    "        model2.fit(X2, y2)\n",
    "        date_test=train_test.loc[train_test['id_road']==id_road]\n",
    "        y_test=date_test[y_columns_list].values # 先取出3个y\n",
    "\n",
    "        X_test=date_test[X_columns_list].values\n",
    "        y0_predict=model0.predict(X_test)\n",
    "        date_test['TTI6']=y0_predict\n",
    "        X1_test=date_test[X1_columns_list].values\n",
    "        y1_predict=model1.predict(X1_test)\n",
    "        date_test['TTI7']=y1_predict\n",
    "        X2_test=date_test[X2_columns_list].values\n",
    "        y2_predict=model2.predict(X2_test)\n",
    "        #y_predict=model.predict(X_test)\n",
    "        #err=np.abs(y_test-y_predict)\n",
    "        #mae+=np.sum(np.sum(err))\n",
    "        err0=np.abs(y_test[:,0]-y0_predict)\n",
    "        err1=np.abs(y_test[:,1]-y1_predict)\n",
    "        err2=np.abs(y_test[:,2]-y2_predict)\n",
    "        mae0=np.sum(err0)\n",
    "        mae1=np.sum(err1)\n",
    "        mae2=np.sum(err2)\n",
    "        print(mae0/len(err0),mae1/len(err1),mae2/len(err2))\n",
    "        mae+=mae0+mae1+mae2\n",
    "    mae/=len(train_test)*3\n",
    "    print(mae)\n",
    "    mae_sum+=mae\n",
    "print(mae_sum/len(month_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1.07123789, 1.08742199, 1.10304319, ..., 1.60532471, 1.62759496,\n       1.55680951])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 训练代码\n",
    "#data_train=['id_road','time','TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','isHoliday','weekday']\n",
    "#Xy_test=['id_road','time','TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','id_sample0','id_sample1','id_sample2','isHoliday','weekday']\n",
    "data_train = df5\n",
    "data_train['hour']=[x.hour+x.minute/60 for x in data_train['time']]    # 只保留小时和分\n",
    "#display(data_train)\n",
    "Xy_test=pd.read_csv('test_6+6+3_more.csv')\n",
    "Xy_test['time']=pd.to_datetime(Xy_test['time'])\n",
    "Xy_test['hour']=[x.hour+x.minute/60 for x in Xy_test['time']]    # 只保留小时和分\n",
    "y_predict=np.zeros(Xy_test.shape[0]*3)\n",
    "for id_road,group in Xy_test.groupby('id_road'):\n",
    "    group_train=data_train.loc[data_train['id_road']==id_road]\n",
    "    X_columns_list=['TTI0','TTI1','TTI2','TTI3','TTI4','TTI5','speed0','speed1','speed2','speed3','speed4','speed5','hour']\n",
    "    y_columns_list=['TTI6','TTI7','TTI8']\n",
    "    X=group_train[X_columns_list].values\n",
    "    y=group_train[y_columns_list].values\n",
    "    y0=y[:,0]\n",
    "    y1=y[:,1]\n",
    "    y2=y[:,2]\n",
    "    model0= LGBMRegressor(num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    model1= LGBMRegressor(num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    model2= LGBMRegressor(num_leaves=31,max_depth=7,learning_rate=0.02,n_estimators=500,min_child_samples=22)\n",
    "    model0.fit(X, y0)\n",
    "    model1.fit(X, y1)\n",
    "    model2.fit(X, y2)\n",
    "    id_sample_columns_list=['id_sample0','id_sample1','id_sample2']\n",
    "    X_test=group[X_columns_list].values\n",
    "    id_sample=group[id_sample_columns_list].values\n",
    "    y0_predict=model0.predict(X_test)\n",
    "    y1_predict=model1.predict(X_test)\n",
    "    y2_predict=model2.predict(X_test)\n",
    "    \n",
    "    for i in range(np.size(y0_predict)):\n",
    "        y_predict[int(id_sample[i,0])]=y0_predict[i]\n",
    "        y_predict[int(id_sample[i,1])]=y1_predict[i]\n",
    "        y_predict[int(id_sample[i,2])]=y2_predict[i]\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出y_predict\n",
    "out=np.zeros([len(y_predict),2])\n",
    "for i in range(len(y_predict)):\n",
    "    out[i,0]=i\n",
    "    out[i,1]=y_predict[i]\n",
    "out=pd.DataFrame(out,columns=['id_sample','TTI'])\n",
    "out.to_csv('submit19.csv',mode='w',index=False,header=True,encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit3778a1df396b4d6c9e4b8a52fb936000",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}